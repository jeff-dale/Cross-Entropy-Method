{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib; matplotlib.use(\"tkagg\")\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    \"\"\"\n",
    "    Optimize a function using the Cross Entropy method. Adapted from:\n",
    "    http://www.cleveralgorithms.com/nature-inspired/probabilistic/cross_entropy.html\n",
    "    \"\"\"\n",
    "\n",
    "    CURVE_DENSITY = 40\n",
    "\n",
    "\n",
    "    def __init__(self, dimension: int, bounds: np.ndarray, max_iterations: int, num_samples: int, num_update: int, learning_rate: float, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize parameters for Cross Entropy method of optimization.\n",
    "\n",
    "        :param dimension: number of dimensions to optimize.\n",
    "        :param bounds: list of tuples of upper/lower bounds. List is the same size as dimension.\n",
    "        :param max_iterations: maximum number of iterations in performing optimization.\n",
    "        :param num_samples: number of samples in Monte Carlo simulation.\n",
    "        :param num_update: number of samples to consider when updating distribution.\n",
    "        :param learning_rate: speed of convergence.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.bounds = bounds.astype(np.float64)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.num_samples = num_samples\n",
    "        self.num_update = num_update\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # initialize results to empty, will be set after optimization\n",
    "        self.bests = []\n",
    "        self.averages = []\n",
    "\n",
    "        # kwargs for compatibility of **params in main function\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "\n",
    "    def optimize(self, objective_function: callable, do_print: bool = False) -> (np.ndarray, list):\n",
    "        \"\"\"\n",
    "        Optimizes given objective function.\n",
    "\n",
    "        :param objective_function: function to optimize\n",
    "        :param do_print: toggle output on and off\n",
    "        :return: best solution, list of individuals by iteration\n",
    "        \"\"\"\n",
    "\n",
    "        # Randomly initialize means within given bounds\n",
    "        means = self.bounds[:, 0] + np.multiply(\n",
    "            np.random.rand(self.dimension),\n",
    "            self.bounds[:, 1] - self.bounds[:, 0]\n",
    "        )\n",
    "\n",
    "        # Initialize standard deviations as range of bounds\n",
    "        standard_deviations = self.bounds[:, 1] - self.bounds[:, 0]\n",
    "        standard_deviations = standard_deviations.astype(np.float64)\n",
    "\n",
    "        # Initialize current best to None\n",
    "        best_individual = None\n",
    "        best_cost = None\n",
    "\n",
    "        # Intialize stuff for plotting\n",
    "        best_by_iteration = []\n",
    "        average_by_iteration = []\n",
    "\n",
    "        samples_by_iteration = []\n",
    "\n",
    "        # Iterate until convergence or until max iterations is reached\n",
    "        for iteration in range(self.max_iterations):\n",
    "\n",
    "            # Generate samples from a Gaussian distribution between bounds\n",
    "            samples = np.asarray(\n",
    "                [[max(min(np.random.normal(means[i], standard_deviations[i]), self.bounds[i, 1]), self.bounds[i, 0]) for i in range(self.dimension)] for _ in range(self.num_samples)]\n",
    "            )\n",
    "            sample_costs = objective_function(samples)\n",
    "\n",
    "            # Sort samples and sample costs by index\n",
    "            sorted_indices = sample_costs.argsort()\n",
    "            samples = samples[sorted_indices]\n",
    "            sample_costs = sample_costs[sorted_indices]\n",
    "\n",
    "            # Update best individual if we have discovered a new best\n",
    "            if best_individual is None or best_cost > sample_costs[0]:\n",
    "                best_individual, best_cost = samples[0], sample_costs[0]\n",
    "\n",
    "            # Select individuals to influence distribution\n",
    "            selected_individuals = samples[:self.num_update]\n",
    "\n",
    "            # Update distribution parameters\n",
    "            for i in range(self.dimension):\n",
    "                means[i] = self.learning_rate * means[i] + ((1.0-self.learning_rate) * np.mean(selected_individuals[:, i]))\n",
    "                standard_deviations[i] = self.learning_rate * standard_deviations[i] + ((1.0-self.learning_rate) * np.std(selected_individuals[:, i]))\n",
    "\n",
    "            # Display status of algorithm\n",
    "            if do_print:\n",
    "                print(\"Iteration {iteration}\\t\\tBest cost: {fitness}\\t\\tBest individual: {individual}\".format(\n",
    "                    iteration=str.zfill(str(iteration), 3),\n",
    "                    fitness=repr(best_cost),\n",
    "                    individual=repr(best_individual)\n",
    "                ))\n",
    "\n",
    "            samples_by_iteration.append(samples)\n",
    "            best_by_iteration.append(best_cost)\n",
    "            average_by_iteration.append(np.mean(sample_costs))\n",
    "\n",
    "        self.bests.append(best_by_iteration)\n",
    "        self.averages.append(average_by_iteration)\n",
    "\n",
    "        return best_individual, samples_by_iteration\n",
    "\n",
    "\n",
    "    def plot_reps(self, title, random_search_avg: list = None, random_search_best: list = None) -> None:\n",
    "        \"\"\"\n",
    "        Plot all reps with global best solutions.\n",
    "\n",
    "        :param title: suptitle of plot\n",
    "        :param random_search_avg: average fitness value for random search across generations\n",
    "        :param random_search_best: best fitness value for random search by generation\n",
    "        :return: void\n",
    "        \"\"\"\n",
    "\n",
    "        is_random_search = not (random_search_avg is None or random_search_best is None)\n",
    "\n",
    "        plt.subplots(1, 2, figsize=(16, 8))\n",
    "        plt.suptitle(title)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Average Cost by Iteration\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Average Cost\")\n",
    "\n",
    "        num_reps = len(self.averages)\n",
    "\n",
    "        # plot each rep\n",
    "        for rep in range(num_reps):\n",
    "            plt.plot(range(len(self.averages[rep])), self.averages[rep], label=\"Rep %d Average\" % (rep + 1))\n",
    "\n",
    "        if is_random_search:\n",
    "            plt.plot(range(len(random_search_avg)), random_search_avg, label=\"Random Search Average\")\n",
    "            # plt.plot(range(len(random_search_best)), random_search_best, label=\"Random Search Best\")\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Lowest Cost by Iteration\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Best Cost\")\n",
    "\n",
    "        # plot each rep\n",
    "        for rep in range(num_reps):\n",
    "            plt.plot(range(len(self.bests[rep])), self.bests[rep], label=\"Rep %d Best\" % (rep + 1))\n",
    "\n",
    "        if is_random_search:\n",
    "            plt.plot(range(len(random_search_best)), random_search_best, label=\"Random Search Best\")\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "\n",
    "\n",
    "    def __init__(self, dimension: int, bounds: np.ndarray, max_iterations: int, num_samples: int, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize parameters for Random Search benchmark.\n",
    "\n",
    "        :param dimension: number of dimensions to optimize.\n",
    "        :param bounds: list of tuples of upper/lower bounds. List is the same size as dimension.\n",
    "        :param max_iterations: maximum number of iterations in performing optimization.\n",
    "        :param num_samples: number of samples in Monte Carlo simulation.\n",
    "        :param num_update: number of samples to consider when updating distribution.\n",
    "        :param learning_rate: speed of convergence.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.bounds = bounds.astype(np.float64)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # unused, just for compatibility with initializing CE and RS with same **params\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "\n",
    "    def optimize(self, objective_function: callable, do_print: bool = False) -> (np.ndarray, list):\n",
    "        \"\"\"\n",
    "        Optimizes given objective function.\n",
    "\n",
    "        :param objective_function: function to optimize\n",
    "        :return: best solution, list of individuals by iteration\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize current best to None\n",
    "        best_individual = None\n",
    "        best_cost = None\n",
    "\n",
    "        # Intialize stuff for plotting\n",
    "        best_by_iteration = []\n",
    "        average_by_iteration = []\n",
    "\n",
    "        samples_by_iteration = []\n",
    "\n",
    "\n",
    "        # Iterate until convergence or until max iterations is reached\n",
    "        for iteration in range(self.max_iterations):\n",
    "\n",
    "            # Generate samples from a Gaussian distribution between bounds\n",
    "            samples = np.asarray(\n",
    "                [[max(min(self.bounds[i, 0] + np.random.rand()*(self.bounds[i, 1] - self.bounds[i, 0]), self.bounds[i, 1]), self.bounds[i, 0]) for\n",
    "                  i in range(self.dimension)] for _ in range(self.num_samples)]\n",
    "            )\n",
    "            sample_costs = objective_function(samples)\n",
    "\n",
    "            # Sort samples and sample costs by index\n",
    "            sorted_indices = sample_costs.argsort()\n",
    "            samples = samples[sorted_indices]\n",
    "            sample_costs = sample_costs[sorted_indices]\n",
    "\n",
    "            # Update best individual if we have discovered a new best\n",
    "            if best_individual is None or best_cost > sample_costs[0]:\n",
    "                best_individual, best_cost = samples[0], sample_costs[0]\n",
    "\n",
    "            # Display status of algorithm\n",
    "            if do_print:\n",
    "                print(\"Iteration {iteration}\\t\\tBest cost: {fitness}\\t\\tBest individual: {individual}\".format(\n",
    "                    iteration=str.zfill(str(iteration), 3),\n",
    "                    fitness=repr(best_cost),\n",
    "                    individual=repr(best_individual)\n",
    "                ))\n",
    "\n",
    "            samples_by_iteration.append(samples)\n",
    "            best_by_iteration.append(best_cost)\n",
    "            average_by_iteration.append(np.mean(sample_costs))\n",
    "\n",
    "\n",
    "        return best_individual, samples_by_iteration, best_by_iteration, average_by_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rastrigin(x: np.ndarray, A: float = 10, n: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Benchmark function with many local optima.\n",
    "    Global minimum is at x = 0.\n",
    "    Bounds: (-5.12, 5.12)\n",
    "\n",
    "    :param x: input vector\n",
    "    :param A: arbitrary constant, typically A=10\n",
    "    :param n: number of dimensions\n",
    "    :return: value of Rastrigin function\n",
    "    \"\"\"\n",
    "    total = np.ones((x.shape[0]))*A*n\n",
    "    for i in range(n):\n",
    "        total += (np.power(x[:, i], 2) - A*np.cos(2*np.pi*x[:, i]))\n",
    "    return total.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Ackley(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Ackley function for benchmarking.\n",
    "    Global minimum at (0, 0).\n",
    "    Bounds: (-5, 5)\n",
    "\n",
    "    :param x: input vector, must be 2D\n",
    "    :return: value of Ackley function\n",
    "    \"\"\"\n",
    "    return -20*np.exp(-0.2*np.sqrt(0.5*(np.power(x[:, 0], 2) + np.power(x[:, 1], 2)))) - \\\n",
    "        np.exp(0.5*(np.cos(2*np.pi*x[:, 0]) + np.cos(2*np.pi*x[:, 1]))) + np.e + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Easom(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Easom function for benchmarking.\n",
    "    Global minimum at f(pi, pi) = -1\n",
    "    Bounds: (-100, 100)\n",
    "\n",
    "    :param x: input vector, must be 2D\n",
    "    :return: value of Easom function\n",
    "    \"\"\"\n",
    "    return -np.cos(x[:, 0])*np.cos(x[:, 1])*np.exp(-(np.power(x[:, 0] - np.pi, 2) + np.power(x[:, 1] - np.pi, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cross_in_Tray(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Cross-in-tray function for benchmarking.\n",
    "    Global minimums at f(+- 1.34941, +-1.34941) = -2.06261\n",
    "    Bounds: (-10, 10)\n",
    "\n",
    "    :param x: input vector, must be 2D\n",
    "    :return: value of Cross_in_Tray function\n",
    "    \"\"\"\n",
    "    return -0.0001*np.power(np.abs(np.sin(x[:, 0])*np.sin(x[:, 1])*np.exp(np.abs(100-np.sqrt(np.power(x[:, 0], 2) + np.power(x[:, 1], 2))/np.pi))) + 1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Levi(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Levi function for benchmarking.\n",
    "    Global minimum at f(0, 0) = 0\n",
    "    Bounds: (-5, 5)\n",
    "    \n",
    "    :param x: input vector, must be 2D\n",
    "    :return: value of Levi function\n",
    "    \"\"\"\n",
    "    return np.power(np.sin(3*np.pi*x[:, 0]), 2) + np.multiply(np.power(x[:, 0] - 1, 2), 1+np.power(np.sin(3*np.pi*x[:, 1]), 2))+np.multiply(np.power(x[:, 1]-1, 2), 1+np.power(np.sin(2*np.pi*x[:, 1]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def animate(objective_function: callable, samples_by_iteration, bounds: np.ndarray, curve_density: int):\n",
    "\n",
    "    # Precalculate surface points for plotting\n",
    "    xs = np.linspace(bounds[0][0], bounds[0][1], curve_density).reshape(\n",
    "        (1, curve_density))\n",
    "    ys = np.linspace(bounds[1][0], bounds[1][1], curve_density).reshape(\n",
    "        (1, curve_density))\n",
    "    X, Y = np.meshgrid(xs, ys)\n",
    "    Z = objective_function(np.vstack((np.ravel(X), np.ravel(Y))).T).reshape(X.shape)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    samples = fig.add_subplot(111, projection=\"3d\")\n",
    "    samples.plot_surface(X, Y, Z, color=(1, 1, 0, 0.5))\n",
    "    individuals = samples.scatter(samples_by_iteration[0][:, 0], samples_by_iteration[0][:, 1], objective_function(samples_by_iteration[0]), c=(0, 0, 0), s=100)\n",
    "\n",
    "\n",
    "    def init():\n",
    "        return samples,\n",
    "\n",
    "    def iterate(i):\n",
    "        nonlocal individuals\n",
    "        individuals.remove()\n",
    "        individuals = samples.scatter(samples_by_iteration[i][:, 0], samples_by_iteration[i][:, 1], objective_function(samples_by_iteration[i]), c=(0, 0, 0), s=100)\n",
    "        return samples,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, iterate, init_func=init, frames=len(samples_by_iteration), interval=40, blit=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'attributes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5ea1bd173f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mCE_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCE_samples_by_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCE_samples_by_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bounds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURVE_DENSITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross Entropy on %s Function (α=%.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRS_average_by_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRS_best_by_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ec9d6e4d858f>\u001b[0m in \u001b[0;36manimate\u001b[0;34m(objective_function, samples_by_iteration, bounds, curve_density)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0manim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuncAnimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_by_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jeff/Utilities/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeff/Utilities/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmanagers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jeff/Utilities/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# Raise the new window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-topmost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-topmost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'attributes'"
     ]
    }
   ],
   "source": [
    "objective_functions = {\n",
    "    \"Sphere\": {\"f\": lambda x: np.sum((np.power(x, 2)), axis=1), \"bounds\": np.asarray([[-5, 5], [-5, 5]])},\n",
    "    \"Rastrigin\": {\"f\": Rastrigin, \"bounds\": np.asarray([[-5, 5], [-5, 5]])},\n",
    "    \"Ackley\": {\"f\": Ackley, \"bounds\": np.asarray([[-5.12, 5.12], [-5.12, 5.12]])},\n",
    "    \"Easom\": {\"f\": Easom, \"bounds\": np.asarray([[-100, 100], [-100, 100]])},\n",
    "    \"Cross in Tray\": {\"f\": Cross_in_Tray, \"bounds\": np.asarray([[-10, 10], [-10, 10]])},\n",
    "    \"Levi\": {\"f\": Levi, \"bounds\": np.asarray([[-10, 10], [-10, 10]])}\n",
    "}\n",
    "\n",
    "objective_function = \"Levi\"\n",
    "\n",
    "params = {\n",
    "    \"dimension\": 2,\n",
    "    \"bounds\": objective_functions[objective_function][\"bounds\"],\n",
    "    \"max_iterations\": 100,\n",
    "    \"num_samples\": 50,\n",
    "    \"num_update\": 5,\n",
    "    \"learning_rate\": 0.7,\n",
    "    \"num_reps\": 1\n",
    "}\n",
    "\n",
    "CE = CrossEntropy(**params)\n",
    "RS = RandomSearch(**params)\n",
    "\n",
    "RS_best, RS_samples_by_iteration, RS_best_by_iteration, RS_average_by_iteration = RS.optimize(objective_functions[objective_function][\"f\"])\n",
    "CE_bests, CE_averages = [], []\n",
    "\n",
    "CE_best, CE_samples_by_iteration = None, None\n",
    "for rep in range(params[\"num_reps\"]):\n",
    "    CE_best, CE_samples_by_iteration = CE.optimize(objective_functions[objective_function][\"f\"], do_print=False)\n",
    "\n",
    "animate(objective_functions[objective_function][\"f\"], CE_samples_by_iteration, params[\"bounds\"], CrossEntropy.CURVE_DENSITY)\n",
    "#CE.plot_reps(\"Cross Entropy on %s Function (α=%.2f)\" % (objective_function, params[\"learning_rate\"]), RS_average_by_iteration, RS_best_by_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
